\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{times}
\usepackage{graphics,graphicx}
\usepackage{denselists}
\renewcommand\rmdefault{phv}

\begin{document}
\title{ITKv4 A2D2 Final Project Report\\ {\Large ITK Algorithms for Analyzing Time-Varying Shape with Application to
  Longitudinal Heart Modeling} }
\date{October 19, 2012}
\author{Joshua Cates and P. Thomas Fletcher\\Scientific Computing and
  Imaging Institute\\University of Utah}

 \maketitle
\thispagestyle{empty}
\vspace*{-24pt} 

\section{Project Description}
The goal of this project was to implement algorithms within the
Insight Toolkit (v4) for the longitudinal shape analysis (LSA) of
three-dimensional anatomical shape. The modeling and statistical
analysis of longitudinal shape changes has a wide range of biomedical
applications, including understanding normal versus abnormal
anatomical development, characterizing degenerative changes due to
disease, and modeling motion such as breathing or the heart
cycle. This project's contribution to ITK is a general software
framework for constructing statistical models of sets of shapes from
image data. The framework includes a mixed-effects model for analyzing
longitudinal shape change. Such models offer increased statistical
power over standard regression or simple averaging of individual
trends. 

Our longitudinal shape analysis method is based on mixed-effects
models, pioneered by Laird and Ware (CITATION INLINE HERE?,
1982). These models are hierarchical, characterizing each individual
trend as a variation from a linear model of the overall population
trend. While mixed-effects models are commonly used for simple
univariate or low-dimensional data, the data coming from medical
images, such as anatomical shape data, is typically much more complex
and high-dimensional. This high dimensionality presents problems in
the estimation of standard mixed-effects models. We have recently
developed a mixed-effects model of anatomical shape that successfully
overcomes these issues by optimizing the shape representation to
provide the simplest, or lowest entropy, description of the
population.

At the University of Utah, driving applications for LSA algorithm
development include MRI studies of both patients with atrial
fibrillation (AF) and animal models of AF progression.  These studies
are ongoing at the Comprehensive Arrhythmia Research and Management
Center (CARMA) at the University of Utah.  As a validation and
additional contribution of this work, we have also contributed
anonymized longitudinal patient data from AF patients from the CARMA
Center.

 % More and more, clinical and biomedical studies are turning to
 % collecting longitudinal imaging data to understand biological
 % processes that change over time, including development, aging, or
 % response to a treatment. A major reason for this focus on
 % longitudinal studies is the realization that cross-sectional studies,
 % where individuals are only measured once, are unable to capture the
 % effects of growth or change even when the subjects in the study have
 % a wide range of ages. This is because the trends in a population
 % related to age do not necessarily reflect the changes that any one
 % individual may undergo. New image analysis methods and software
 % infrastructure are needed for understanding longitudinal data,
 % including tasks such as tracking temporal changes within an
 % individual, detecting abnormal progression, and quantifying the
 % differences between group trends. Along these lines, we propose to
 % add to ITK a software infrastructure for longitudinal shape analysis
 % (LSA), which we will validate by building longitudinal heart shape
 % models from MRI data of atrial fibrillation patients.


\section{Project Outcomes and Deliverables}
\subsection{The ITKParticleShapeModeling external ITKv4 module}
The LSA algorithm relies on dynamic point-based representations of
shape surfaces known as {\em particle systems}.  Given a set of image
segmentations, the LSA algorithm constructs a particle-system surface
representation for each shape, while simultaneously generating a shape
model for the population.  The shape model is constructed through an
optimization process on the particle representation that produces a
statistically compact model that best fits the data.

To implement our shape modeling framework within ITK, we developed the
ITKParticleShapeModeling external module for ITK, which is consists of
the follow classes and frameworks.  All code has been written to the
ITK coding standards.  For more a more detailed list of
specific classes and Doxygen documentation, please see the official
public repository for the ITKParticleShapeModeling project on GitHub
at \texttt{https://github.com/joshcates/ITKParticleShapeModeling}.
\begin{itemize}
\item {\em Particle system data container.}  A subclass of
  itk::Object, the itk::PSMParticleSystem data container is a facade
  class that manages point-based representations of implicit shape
  surfaces, including particle position information and the domains
  (image volumes and coordinate spaces) in which particles are
  defined.  The PSMParticleSystem class makes use of ITK's
  command/observer framework to enable particle system updates to
  trigger attached processes, such as visualization events at the
  application level.
\item{\em Optimizers and Cost functions.}  The shape modeling
  algorithms rely on a gradient-descent minimization of a set of cost
  functions on the particle-system representations of shape surfaces.
\item{\em Shape modeling filters.} These classes are itk::ProcessObjects that
  combine the optimizers, cost functions, and particle system representations
  to implement the shape modeling algorithms.  There are three
  classes:
  \begin{enumerate}
  \item PSMEntropyModelFilter provides for cross-sectional
    shape analysis with multiscale optimization and is the base class
    for other shape modeling filters.
  \item PSMEntropyRegressionModelFilter produces a linear
    regression shape model.
  \item PSMEntropyMixedEffectsModelFilter implements the full LSA
    algorithm for longitudinal mixed-effects modeling.
  \end{enumerate}
\item{\em Additional particle-system infrastructure.}  The cost functions
  and optimizers rely on some additional infrastructure to
  manipulate the particle system data and produce optimized models.  This
  additional infrastructure includes classes for computing particle
  neighborhoods.
\item{\em Application-level code support for file and parameter
    management.}  The use of the shape modeling algorithms requires
  wrangling many image inputs and point-set outputs, as well as
  specifying parameters across multiple scales of optimization.  To
  facilitate development of applications with these filters, we have
  included some support for reading XML-based descriptions of shape
  modeling projects and examples of simple applications in the testing
  and Examples section. 
\item{\em Regression Test Code and Documentation.}  Regression tests are ITK
  Dashboard-enabled tests of the classes included in the
  ITKParticleShapeModeling module.  We have also created Doxygen
  class-level documentation.
\item{\em Preprocessing filters.}  We have included several filters
  that can be used for -- or serve as examples for -- preprocessing of image
  segmentations to produce suitable distance transform inputs to our
  shape analysis filters.
\end{itemize} 

Figure~\ref{fig:modules} depicts a conceptual view of how the code
modules are combined to implement a data flow pipeline for
longitudinal shape analysis.  These ITK modules constitute a
general shape modeling framework, in which new cost functions and
optimizer classes can be substituted to produce a wide variety of
shape modeling algorithms.  For the LSA algorithm, the data flow
pipeline output is a set of particle-system surface representations
for each shape, as well as the population and individual shape trends
estimated in the longitudinal mixed-effects model.
\begin{figure}[tb]
\centering
%\includegraphics[width=0.8\textwidth]{LSAFig.pdf} 
\caption{\label{fig:modules}A data-flow pipeline for ITKParticleShapeModeling classes.}
\end{figure}

In addition to shape analysis applications, the PSMParticleSystem
class and optimization framework may be useful building blocks for
other image processing and visualization algorithms.  The module
includes a set of objects that can be used to generate robust particle
system surface representations, for example, which can be used in a
variety of mesh generation, surface visualization and simulation
applications. Thus, the proposed deliverables have potential benefits
to the ITK community that extend well beyond shape analysis.

\subsection{Clinical Data Contributions}
In addition to the ITKParticleShapeModeling module, we have contributed
60 anonymized datasets as an example case for from our clinical atrial
fibrillation patient database at the CARMA Center.  These data consist
of manual expert segmentations of the left atrium of the heart for
patients that have undergone radiofrequency ablation.  The timepoints
that are represented are pre-ablation and, variously, 6, 12, and 24
months post-ablation.  These datasets are publicly available from the
Insight Journal MIDAS repository at the following url
\texttt{http://hdl.handle.net/1926/1764}.

\subsection{Ongoing and Future Work}
The methodologies implemented in this ITKv4 module are in active use
for research and development at the SCI Institute and by other groups
within both the University of Utah and at the University of North
Carolina, Chapel Hill.  Research at the CARMA Center includes
investigation of both the basic physiological mechanisms for atrial
fibrillation and clinical applications of shape models.  To support
ongoing research efforts and the advancement of the shape analysis
methodologies, we are planning several new ITKParticleShapeModeling
features, including the following:
\begin{itemize}
\item Extension to modeling of open surfaces.
\item Extension to mesh-based surface representations.
\item Algorithmic work to speed up model optimization.
\item Graphical user interface example applications to facilitate use
  by domain researchers.
\end{itemize}

% \vspace*{-12pt}
% \paragraph{Validation of Shape Analysis Framework}
% As a test bed and proof of concept for the longitudinal shape representation, we
% propose to apply the LSA framework to model the changes that occur in the left
% atrium in patients with atrial fibrillation.  Atrial fibrillation (AF) is a
% growing problem in modern societies with an enormous impact on both short term
% quality of life and long-term survival~\cite{RSM:Cal2007}. Approximately 0.5\%
% of people aged 50--59 have atrial fibrillation and of those aged 80--89, 9\% are
% afflicted with AF---and these prevalence are increasing~\cite{RSM:Ben98}.  The
% basis of AF lies in the altered electrical coupling of cells in the atria, which
% progresses more or less slowly with age so that most of the elderly are assumed
% to have some change in the tissue substrate.  In some cases, advanced levels of
% this substrate alteration results in uncontrolled and unsynchronized spread of
% electrical activity; the effects on contraction include a marked reduction in
% blood flow not only from the atria but also from the ventricles, resulting in a
% drop in cardiac output.  Successful cures for AF require the electrical
% isolation of regions of the atria, particularly the pulmonary veins and
% posterior wall of the left atrium.  To achieve this separation, a method called
% pulmonary vein antrum isolation (PVAI) has become the standard of clinical care
% and is the topic of considerable research and industrial
% interest~\cite{RSM:Hai2000, RSM:Pap2000, RSM:Mar2002, RSM:Mar2003, RSM:Che2004,
%   RSM:Gil2005, RSM:Gil2006, RSM:Kil2006, RSM:Bad2009}.  Modern PVAI, known also
% as radio frequency (RF) ablation, depends on applying radio frequency energy to
% the inner surface of the left atrium by means of catheters introduced into the
% veins and advanced under image guidance to the heart.

% The shape of the left atrium changes during the progression of AF, becoming
% dilated as the patient spends more time in episodes of AF.  There are
% indications that shape can be at least partially restored following PVAI, and to
% evaluate such changes, a quantitative shape analysis like that proposed here is
% essential.  Current methods of evaluating shape are limited to crude estimates
% of cross sectional dimensions of the left atrium or image based determination of
% left atrial volume.  More advanced statistical analysis of shape in the
% longitudinal setting of disease progression and recovery following PVAI would
% provide patient specific means of, for example, diagnosing presence of and
% progression of the disease.  By following the recovery of shape in patients
% treated with PVAI, it would be possible to determine effectiveness of the
% therapy and anticipate the need for repeated interventions.

% \paragraph{Scope} The proposed software for longitudinal shape analysis (LSA)
% will consist of all of the necessary modules to compute LSA models from a
% collection of image segmentations and statistically analyze the results.  We
% will also provide appropriate documentation in the ITK style and ITK Dashboard
% regression test code.  To serve as both a tutorial and a validation of the LSA
% implementation, we will contribute example code and documentation for running
% the LSA algorithms on the longitudinal MRI heart data.  The heart data will
% also be made available.
% \vspace*{-12pt}

\section{ITKv4 Beta Testing Feedback}
A major motivation for this project was to beta test new ITKv4
software for robustness and extensibility.  In this section we report
on the ITKv4 infrastructure that we utilized in our software
development and provide specific feedback on strengths and weaknesses
of the ITKv4 codebase.

\subsection{General Feedback}
In general, we are happy to report that the fundamentals of ITKv4 are
sound.  During our project development, we encountered very few
problems using the basic image and pipeline processing modules.
However, we did encounter a few roadblocks when exploring the use of
some of the newer modules, which are summarized in the next section.

For ITK to continue to fulfill its mission to support innovation in
image processing, its core components must remain as flexible and
general as possible.  However, as the state of the art in image
processing progresses, there is an inevitable shift towards more and
more complex and specialized code frameworks (e.g. our own
ITKParticleShapeModeling module).  For this reason, we are happy to
see the shift towards a more modularized codebase in ITKv4.
Modularization will help to manage the change and complexity to come,
enabling a process of ``natural selection'' for ITK code.  Frameworks
that prove useful will be maintained, while those that are too
specialized or otherwise go unused will be easy to prune or spin out
into separate projects.

\subsection{Specific Feedback}
\begin{itemize}

\item Our experience as ITKv4 beta testers suggests that there will
  continue to be a use for the more basic frameworks in ITK, such as
  the original registration and level-set code.  We were happy to see
  these frameworks retained in ITKv4.

\item We found the optimization frameworks in ITK, including
  both the original and ITKv4 versions, to be too specific to image
  registration to be very useful for our optimization application.
  This is not necessary a shortcoming of the toolkit, since these
  frameworks were designed pretty much exclusively with image
  registration in mind, but it is worth noting for future development.
  After careful scrutiny, we decided that the work to implement our
  own particle-system-specific gradient descent optimizer and cost
  function hierarchy was justified, given the number of specific
  callback hooks and optimization criteria required for our purposes.

\item We were originally very keen to utilize some
  of the functionality in the new LabelMap module, which appears to provide
  some of what we need for our segmentation preprocessing
  algorithms. Unfortunately, we had difficulty compiling this code and
  it did not perform as expected. (Note however, thats our experience
  with this code was before the official Beta release, so it is
  possible this code has been fixed since.)

\end{itemize}


\end{document}

